{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23fb207e-c2ed-4c63-b604-8b65f8a59a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Dual SVM with C=0.1145475372279496...\n",
      "\n",
      "Weight Vector (w_dual) for C=0.1145475372279496: [-2.50258300e+00 -1.36379421e+00 -1.78226257e+00  2.46114918e-03]\n",
      "Bias (b_dual) for C=0.1145475372279496: 5.43990657642657\n",
      "Train Error (C=0.1145475372279496): 0.026376146788990827\n",
      "Test Error (C=0.1145475372279496): 0.024\n",
      "\n",
      "Training Dual SVM with C=0.572737686139748...\n",
      "\n",
      "Weight Vector (w_dual) for C=0.572737686139748: [-0.501384   -0.2730924  -0.35727902  0.00075264]\n",
      "Bias (b_dual) for C=0.572737686139748: 1.0504399510077336\n",
      "Train Error (C=0.572737686139748): 0.02408256880733945\n",
      "Test Error (C=0.572737686139748): 0.022\n",
      "\n",
      "Training Dual SVM with C=0.8018327605956472...\n",
      "\n",
      "Weight Vector (w_dual) for C=0.8018327605956472: [-0.35818195 -0.19507173 -0.25521849  0.00053823]\n",
      "Bias (b_dual) for C=0.8018327605956472: 0.7534787228568641\n",
      "Train Error (C=0.8018327605956472): 0.02408256880733945\n",
      "Test Error (C=0.8018327605956472): 0.022\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path, header=None)\n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "    y = 2 * y - 1  # Convert labels to {1, -1}\n",
    "    return X, y\n",
    "\n",
    "def dual_objective(alphas, X, y, C):\n",
    "    m = len(y)\n",
    "    term1 = 0.5 * np.sum(alphas * alphas)\n",
    "    term2 = -np.sum(alphas)\n",
    "    term3 = 0.5 * np.dot(alphas * y, np.dot(X, X.T) @ (alphas * y))\n",
    "    return term1 + term2 + C * term3\n",
    "\n",
    "def dual_constraint(alphas, y):\n",
    "    return np.sum(alphas * y)\n",
    "\n",
    "def train_dual_svm(X, y, C):\n",
    "    m, n = X.shape\n",
    "    initial_alphas = np.zeros(m)\n",
    "    \n",
    "    # Define the constraints\n",
    "    constraint = {'type': 'eq', 'fun': lambda alphas: dual_constraint(alphas, y)}\n",
    "\n",
    "    # Optimize the dual objective function\n",
    "    result = minimize(dual_objective, initial_alphas, args=(X, y, C), constraints=constraint, method='SLSQP')\n",
    "    \n",
    "    # Extract the Lagrange multipliers (alphas)\n",
    "    alphas = result.x\n",
    "    \n",
    "    # Calculate the weights\n",
    "    w = np.dot(alphas * y, X)\n",
    "    \n",
    "    # Calculate the bias\n",
    "    sv_indices = np.where((alphas > 1e-5) & (alphas < C - 1e-5))[0]\n",
    "    b = np.mean(y[sv_indices] - np.dot(X[sv_indices], w))\n",
    "    \n",
    "    return w, b\n",
    "\n",
    "\n",
    "def predict(X, w, b):\n",
    "    return np.sign(np.dot(X, w) + b)\n",
    "\n",
    "def calculate_error(predictions, labels):\n",
    "    misclassified = np.sum(predictions != labels)\n",
    "    error = misclassified / len(labels)\n",
    "    return error\n",
    "\n",
    "train_file_path = \"C:\\\\Users\\\\bindu\\\\Downloads\\\\Dataset-svm\\\\bank-note\\\\train.csv\"\n",
    "test_file_path = \"C:\\\\Users\\\\bindu\\\\Downloads\\\\Dataset-svm\\\\bank-note\\\\test.csv\"\n",
    "X_train, y_train = load_data(train_file_path)\n",
    "X_test, y_test = load_data(test_file_path)\n",
    "\n",
    "# Set hyperparameter\n",
    "C_values = [100/873, 500/873, 700/873]\n",
    "\n",
    "# Train and evaluate dual SVM for each C value\n",
    "for C in C_values:\n",
    "    print(f\"\\nTraining Dual SVM with C={C}...\\n\")\n",
    "    w_dual, b_dual = train_dual_svm(X_train, y_train, C)\n",
    "    \n",
    "    print(f\"Weight Vector (w_dual) for C={C}: {w_dual}\")\n",
    "    print(f\"Bias (b_dual) for C={C}: {b_dual}\")\n",
    "\n",
    "    # Make predictions on the train set\n",
    "    train_predictions = predict(X_train, w_dual, b_dual)\n",
    "    train_error = calculate_error(train_predictions, y_train)\n",
    "    print(f\"Train Error (C={C}): {train_error}\")\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    test_predictions = predict(X_test, w_dual, b_dual)\n",
    "    test_error = calculate_error(test_predictions, y_test)\n",
    "    print(f\"Test Error (C={C}): {test_error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc06c17-7f2d-4031-ac70-f3fea58e3fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
