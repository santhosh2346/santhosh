{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fb207e-c2ed-4c63-b604-8b65f8a59a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SVM with C=0.1145475372279496...\n",
      "\n",
      "Final Training Error: 0.6274299142920123\n",
      "Final Test Error: 0.6200078351889313\n",
      "Weight Vector: [ 0.13427096 -0.15304207 -0.12302393 -0.06497777 -0.01535376]\n",
      "Bias Term: 0.13427095910214773\n",
      "\n",
      "Training SVM with C=0.572737686139748...\n",
      "\n",
      "Final Training Error: 0.3060021698065688\n",
      "Final Test Error: 0.3121118736028021\n",
      "Weight Vector: [ 0.61627551 -0.32607317 -0.17982843 -0.20292087 -0.01069369]\n",
      "Bias Term: 0.6162755112297509\n",
      "\n",
      "Training SVM with C=0.8018327605956472...\n",
      "\n",
      "Final Training Error: 0.2597421193793294\n",
      "Final Test Error: 0.26719359641019996\n",
      "Weight Vector: [ 0.65818174 -0.35188487 -0.18731698 -0.20593004 -0.00785838]\n",
      "Bias Term: 0.658181741814027\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load dataset from a CSV file and prepare features and labels.\"\"\"\n",
    "    data = pd.read_csv(file_path, header=None)\n",
    "    X = data.iloc[:, :-1].values  # Extract feature matrix\n",
    "    y = data.iloc[:, -1].values  # Extract labels\n",
    "    y = 2 * y - 1  # Transform labels to {-1, 1}\n",
    "    # Add a bias term to the feature matrix\n",
    "    X = np.c_[np.ones(X.shape[0]), X]\n",
    "    return X, y\n",
    "\n",
    "def shuffle_data(X, y):\n",
    "    \"\"\"Shuffle the dataset to randomize order.\"\"\"\n",
    "    indices = np.random.permutation(len(y))\n",
    "    return X[indices], y[indices]\n",
    "\n",
    "def hinge_loss(w, X, y, C):\n",
    "    \"\"\"Compute the hinge loss with regularization.\"\"\"\n",
    "    loss = np.maximum(0, 1 - y * np.dot(X, w))  # Hinge loss: max(0, 1 - y * (w Â· x))\n",
    "    regularizer = 0.5 * np.sum(w[1:] ** 2) / C  # Regularization excludes the bias term\n",
    "    return np.mean(loss) + regularizer\n",
    "\n",
    "def subgradient(w, x, y, C):\n",
    "    \"\"\"Compute the subgradient for a single data point.\"\"\"\n",
    "    if 1 - y * np.dot(w, x) > 0:\n",
    "        gradient = -y * x + np.concatenate(([0], w[1:])) / C  # Include regularization for weights\n",
    "    else:\n",
    "        gradient = np.concatenate(([0], w[1:])) / C\n",
    "    return gradient\n",
    "\n",
    "def svm_sgd(X_train, y_train, X_test, y_test, C, max_epochs, gamma_0):\n",
    "    \"\"\"Train SVM using stochastic gradient descent.\"\"\"\n",
    "    m, n = X_train.shape  # Number of samples and features\n",
    "    w = np.zeros(n)  # Initialize weights\n",
    "    gamma = gamma_0  # Initial learning rate\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        # Shuffle training data at the start of each epoch\n",
    "        X_train, y_train = shuffle_data(X_train, y_train)\n",
    "\n",
    "        for i in range(m):\n",
    "            xi, yi = X_train[i], y_train[i]\n",
    "            gradient = subgradient(w, xi, yi, C)\n",
    "            w -= gamma * gradient  # Update weights using the gradient\n",
    "\n",
    "        # Adjust learning rate with each epoch\n",
    "        gamma = gamma_0 / (1 + epoch)\n",
    "\n",
    "    # Compute final training and testing errors\n",
    "    train_error = hinge_loss(w, X_train, y_train, C)\n",
    "    test_error = hinge_loss(w, X_test, y_test, C)\n",
    "\n",
    "    return w, train_error, test_error\n",
    "\n",
    "train_file_path = \"C:\\\\Users\\\\santhosh\\\\Downloads\\\\Dataset-svm\\\\bank-note\\\\train.csv\"\n",
    "test_file_path = \"C:\\\\Users\\\\santhosh\\\\Downloads\\\\Dataset-svm\\\\bank-note\\\\test.csv\"\n",
    "\n",
    "# Load training and test datasets\n",
    "X_train, y_train = load_data(train_file_path)\n",
    "X_test, y_test = load_data(test_file_path)\n",
    "\n",
    "# Define hyperparameters\n",
    "C_values = [100 / 873, 500 / 873, 700 / 873]  # Regularization constants\n",
    "max_epochs = 100  # Number of epochs\n",
    "gamma_0 = 0.1  # Initial learning rate\n",
    "\n",
    "# Train and evaluate the SVM for different C values\n",
    "for C in C_values:\n",
    "    print(f\"\\nTraining SVM with C={C}...\\n\")\n",
    "    w, train_error, test_error = svm_sgd(X_train, y_train, X_test, y_test, C, max_epochs, gamma_0)\n",
    "\n",
    "    # Display final results\n",
    "    print(f\"Final Training Error: {train_error}\")\n",
    "    print(f\"Final Test Error: {test_error}\")\n",
    "    print(f\"Weight Vector: {w}\")\n",
    "    print(f\"Bias Term: {w[0]}\")  # The bias term is the first element of the weight vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc06c17-7f2d-4031-ac70-f3fea58e3fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
