{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19bd0507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40f66fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = pd.read_csv('Santhosh/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58c5fb3c-e0d6-45a6-908c-4dace7721451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   41     services   married  secondary  no     0  yes no.1   unknown   5  \\\n",
      "0  48  blue-collar    single  secondary  no   312  yes  yes  cellular   3   \n",
      "1  55   technician   married  secondary  no  1938   no  yes  cellular  18   \n",
      "2  54       admin.   married   tertiary  no    59  yes   no  cellular  10   \n",
      "3  34   management    single   tertiary  no  2646   no   no  cellular  14   \n",
      "4  49       admin.  divorced  secondary  no  1709  yes   no   unknown  12   \n",
      "\n",
      "   may  114  2   -1  0.1 unknown.1 no.2  \n",
      "0  feb  369  2   -1    0   unknown   no  \n",
      "1  aug  193  1  386    3   success  yes  \n",
      "2  jul  268  1   -1    0   unknown   no  \n",
      "3  apr  142  1   -1    0   unknown  yes  \n",
      "4  jun  106  1   -1    0   unknown   no  \n"
     ]
    }
   ],
   "source": [
    "print(trainSet.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b8f4b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfed6ca5-7897-4044-8053-0e90b8d53605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                41              0            5          114            2  \\\n",
      "count  4999.000000    4999.000000  4999.000000  4999.000000  4999.000000   \n",
      "mean     40.836767    1396.424685    15.811762   256.248850     2.775555   \n",
      "std      10.695004    3333.735307     8.357794   251.960779     3.018423   \n",
      "min      18.000000   -2604.000000     1.000000     4.000000     1.000000   \n",
      "25%      33.000000      66.000000     8.000000   103.000000     1.000000   \n",
      "50%      38.000000     453.000000    16.000000   180.000000     2.000000   \n",
      "75%      48.000000    1421.000000    21.000000   318.000000     3.000000   \n",
      "max      95.000000  102127.000000    31.000000  3253.000000    37.000000   \n",
      "\n",
      "                -1          0.1  \n",
      "count  4999.000000  4999.000000  \n",
      "mean     37.825965     0.523505  \n",
      "std      97.578028     1.719936  \n",
      "min      -1.000000     0.000000  \n",
      "25%      -1.000000     0.000000  \n",
      "50%      -1.000000     0.000000  \n",
      "75%      -1.000000     0.000000  \n",
      "max     854.000000    41.000000  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "889fb683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth    Test Error (IG) Test Error (ME) Test Error (Gini)\n",
      "1            0.191        0.191        0.191       \n",
      "2            0.195        0.195        0.195       \n",
      "3            0.195        0.195        0.195       \n",
      "4            0.195        0.195        0.195       \n",
      "5            0.195        0.195        0.195       \n",
      "6            0.195        0.195        0.195       \n",
      "7            0.195        0.195        0.195       \n",
      "8            0.195        0.195        0.195       \n",
      "9            0.195        0.195        0.195       \n",
      "10           0.195        0.195        0.195       \n",
      "11           0.195        0.195        0.195       \n",
      "12           0.195        0.195        0.195       \n",
      "13           0.195        0.195        0.195       \n",
      "14           0.195        0.195        0.195       \n",
      "15           0.195        0.195        0.195       \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self, attribute, attributeName, is_leaf, label, depth, info_gain, entropy_parent_attr, parent_attr_val):\n",
    "        self.attribute = attribute\n",
    "        self.attributeName = attributeName\n",
    "        self.children = {}\n",
    "        self.is_leaf = is_leaf\n",
    "        self.label = label\n",
    "        self.depth = depth\n",
    "        self.info_gain = info_gain\n",
    "        self.entropy_parent_attr = entropy_parent_attr\n",
    "        self.parent_attr_val = parent_attr_val\n",
    "\n",
    "    def get_attribute(self):\n",
    "        return self.attribute\n",
    "\n",
    "    def add_child(self, child_node, attr_value):\n",
    "        self.children[attr_value] = child_node\n",
    "    \n",
    "    def predict(self, x):\n",
    "        if self.is_leaf:\n",
    "            return self.label\n",
    "        current_val = x[self.attribute]\n",
    "        if current_val not in self.children.keys():\n",
    "            return self.label\n",
    "        return self.children[current_val].predict(x)\n",
    "\n",
    "    def print_node(self, space=\"\"):\n",
    "        print(f\"{space}Depth: {self.depth}\")\n",
    "        print(f\"{space}Selected Feature: {self.attributeName}\")\n",
    "        print(f\"{space}Information Gain for Parent Feature: {self.info_gain}\")\n",
    "        print(f\"{space}Entropy for Parent Feature: {self.entropy_parent_attr}\")\n",
    "        print(f\"{space}Parent Feature Value: {self.parent_attr_val}\")\n",
    "        print(f\"{space}Label: {self.label}\")\n",
    "        for child in self.children.values():\n",
    "            child.print_node(space + \"\\t\")\n",
    "\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=np.inf):\n",
    "        self.root = None\n",
    "        self.depth = 0\n",
    "        if max_depth < 1:\n",
    "            print(\"max_depth cannot be lower than 1! Setting it to 1.\")\n",
    "            max_depth = 1\n",
    "        self.max_depth = max_depth\n",
    "        self.longest_path_len = 0\n",
    "\n",
    "    def build_tree(self, X, Y, attribute_names, attribute_list=[], current_depth=0,\n",
    "                   parent_info={\"max_info_gain\": None, \"attribute_list[max_attribute]\": None, \"value\": None}):\n",
    "        if current_depth > self.longest_path_len:\n",
    "            self.longest_path_len = current_depth\n",
    "        if current_depth >= self.max_depth or len(attribute_list) == 0 or len(np.unique(Y)) == 1:\n",
    "            vals, counts = np.unique(Y, return_counts=True)\n",
    "            return TreeNode(None, None, True, vals[np.argmax(counts)], current_depth,\n",
    "                            parent_info[\"max_info_gain\"], parent_info[\"attribute_list[max_attribute]\"],\n",
    "                            parent_info[\"value\"])\n",
    "\n",
    "        max_info_gain = -1\n",
    "        max_attribute = None\n",
    "        i = 0\n",
    "        for attribute in attribute_list:\n",
    "            info_gain, entropy_attribute, entropy_parent = self.calculate_information_gain(X, Y, attribute)\n",
    "            if info_gain > max_info_gain:\n",
    "                max_info_gain = info_gain\n",
    "                max_attribute = i\n",
    "                entropy = entropy_parent\n",
    "            i += 1\n",
    "\n",
    "        vals, counts = np.unique(Y, return_counts=True)\n",
    "        root = TreeNode(attribute_list[max_attribute], attribute_names[attribute_list[max_attribute]],\n",
    "                        False, vals[np.argmax(counts)], current_depth,\n",
    "                        parent_info[\"max_info_gain\"], parent_info[\"attribute_list[max_attribute]\"],\n",
    "                        parent_info[\"value\"])\n",
    "\n",
    "        attribute_values = np.unique(X[:, attribute_list[max_attribute]])\n",
    "        new_attribute_list = np.delete(attribute_list, max_attribute)\n",
    "        for value in attribute_values:\n",
    "            indices = np.where(X[:, attribute_list[max_attribute]] == value)[0]\n",
    "            if len(indices) == 0:\n",
    "                root.add_child(TreeNode(None, None, True, vals[np.argmax(counts)], current_depth + 1,\n",
    "                                        max_info_gain, attribute_list[max_attribute], value), current_depth)\n",
    "            else:\n",
    "                parent_info = {\n",
    "                    \"max_info_gain\": max_info_gain,\n",
    "                    \"attribute_list[max_attribute]\": entropy,\n",
    "                    \"value\": value\n",
    "                }\n",
    "                root.add_child(self.build_tree(X[indices], Y[indices], attribute_names, new_attribute_list,\n",
    "                                               current_depth + 1, parent_info), value)\n",
    "        return root\n",
    "\n",
    "    def calculate_entropy(self, counts):\n",
    "        total = sum(counts)\n",
    "        entropy_value = 0\n",
    "        for element in counts:\n",
    "            p = (element / total)\n",
    "            if p != 0:\n",
    "                entropy_value -= p * np.log2(p)\n",
    "        return entropy_value\n",
    "\n",
    "    def calculate_information_gain(self, X, Y, attribute):\n",
    "        _, counts = np.unique(Y, return_counts=True)\n",
    "        entropy_attribute = self.calculate_entropy(counts)\n",
    "        entropy_parent = 0\n",
    "        distinct_attr_values = list(set(X[:, attribute]))\n",
    "        for val in distinct_attr_values:\n",
    "            indices = np.where(X[:, attribute] == val)[0]\n",
    "            _, counts = np.unique(Y[indices], return_counts=True)\n",
    "            entr = self.calculate_entropy(counts)\n",
    "            entropy_parent += (len(indices) / len(Y)) * entr\n",
    "        info_gain = entropy_attribute - entropy_parent\n",
    "        return info_gain, entropy_attribute, entropy_parent\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        attribute_names = list(range(X.shape[1]))  # Assume attributes are indexed\n",
    "        attribute_list = np.arange(X.shape[1])\n",
    "        self.root = self.build_tree(X, Y, attribute_names, attribute_list, 0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            predictions.append(self.root.predict(x))\n",
    "        return predictions\n",
    "\n",
    "    def get_longest_path_len(self):\n",
    "        return self.longest_path_len\n",
    "\n",
    "    def get_root_attribute(self):\n",
    "        if self.root:\n",
    "            return self.root.get_attribute()\n",
    "        return None\n",
    "\n",
    "    def print_tree(self):\n",
    "        self.root.print_node(\"\")\n",
    "\n",
    "\n",
    "# Load the corrected data\n",
    "train_df = pd.read_csv(\"Santhosh/train.csv\")\n",
    "X_train = train_df.drop('no.2', axis=1).values  # Corrected target column name\n",
    "y_train = train_df['no.2'].values  # Corrected target column name\n",
    "\n",
    "test_df = pd.read_csv(\"Santhosh/test.csv\")\n",
    "X_test = test_df.drop('no.2', axis=1).values  # Corrected target column name\n",
    "y_test = test_df['no.2'].values  # Corrected target column name\n",
    "\n",
    "# Train and evaluate the Decision Tree Classifier\n",
    "max_depth_range = list(range(1, 16))\n",
    "criterion_list = ['information_gain', 'majority_error', 'gini']\n",
    "results = {criterion: [] for criterion in criterion_list}\n",
    "\n",
    "for criterion in criterion_list:\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    for max_depth in max_depth_range:\n",
    "        model = DecisionTreeClassifier(max_depth=max_depth)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        train_acc = accuracy_score(y_train, y_train_pred)\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "        train_errors.append(1 - train_acc)\n",
    "        test_errors.append(1 - test_acc)\n",
    "\n",
    "    results[criterion] = (train_errors, test_errors)\n",
    "\n",
    "# Print results in a table\n",
    "\n",
    "print('{:<12} {:<12} {:<12} {:<12}'.format('Max Depth', 'Test Error (IG)', 'Test Error (ME)', 'Test Error (Gini)'))\n",
    "for i in range(len(max_depth_range)):\n",
    "    print('{:<12} {:<12.3f} {:<12.3f} {:<12.3f}'.format(\n",
    "        max_depth_range[i],\n",
    "        results['information_gain'][1][i],\n",
    "        results['majority_error'][1][i],\n",
    "        results['gini'][1][i]\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ba7ccc-0365-4c81-83eb-38fa323f6f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca16aca-d7da-4db0-bc89-db4e7f83294c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
