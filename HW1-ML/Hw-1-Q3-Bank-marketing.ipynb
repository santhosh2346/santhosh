{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19bd0507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40f66fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = pd.read_csv('C:/Santhosh/ML/car-4/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b8f4b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "889fb683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth    Train Error  Test Error  \n",
      "1            0.145        0.145       \n",
      "2            0.149        0.149       \n",
      "3            0.149        0.149       \n",
      "4            0.149        0.149       \n",
      "5            0.149        0.149       \n",
      "6            0.149        0.149       \n",
      "7            0.149        0.149       \n",
      "8            0.149        0.149       \n",
      "9            0.149        0.149       \n",
      "10           0.149        0.149       \n",
      "11           0.149        0.149       \n",
      "12           0.149        0.149       \n",
      "13           0.149        0.149       \n",
      "14           0.149        0.149       \n",
      "15           0.149        0.149       \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self, attribute, attributeName, is_leaf, label, depth, info_gain, entropy_parent_attr, parent_attr_val):\n",
    "        self.attribute = attribute\n",
    "        self.attributeName = attributeName\n",
    "        self.children = {}\n",
    "        self.is_leaf = is_leaf\n",
    "        self.label = label\n",
    "        self.depth = depth\n",
    "        self.info_gain = info_gain\n",
    "        self.entropy_parent_attr = entropy_parent_attr\n",
    "        self.parent_attr_val = parent_attr_val\n",
    "\n",
    "    def get_attribute(self):\n",
    "        return self.attribute\n",
    "\n",
    "    def add_child(self, child_node, attr_value):\n",
    "        self.children[attr_value] = child_node\n",
    "    \n",
    "    def predict(self, x):\n",
    "        if self.is_leaf:\n",
    "            return self.label\n",
    "        current_val = x[self.attribute]\n",
    "        if current_val not in self.children.keys():\n",
    "            return self.label\n",
    "        return self.children[current_val].predict(x)\n",
    "\n",
    "    def print_node(self, space=\"\"):\n",
    "        print(f\"{space}Depth: {self.depth}\")\n",
    "        print(f\"{space}Selected Feature: {self.attributeName}\")\n",
    "        print(f\"{space}Information Gain for Parent Feature: {self.info_gain}\")\n",
    "        print(f\"{space}Entropy for Parent Feature: {self.entropy_parent_attr}\")\n",
    "        print(f\"{space}Parent Feature Value: {self.parent_attr_val}\")\n",
    "        print(f\"{space}Label: {self.label}\")\n",
    "        for child in self.children.values():\n",
    "            child.print_node(space + \"\\t\")\n",
    "\n",
    "    def _majority_error(self, X, y, attribute):\n",
    "        values = set(X[attribute])\n",
    "        return sum([(X[attribute] == value).mean() *\n",
    "            (1 - Counter(y[X[attribute] == value]).most_common(1)[0][1] / len(y[X[attribute] == value]))\n",
    "                    for value in values])\n",
    "\n",
    "    def _gini(self, X, y, attribute):\n",
    "        values = set(X[attribute])\n",
    "        gini = 1\n",
    "        for value in values:\n",
    "            p = (X[attribute] == value).mean()\n",
    "            gini -= p**2\n",
    "        return gini\n",
    "\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=np.inf):\n",
    "        self.root = None\n",
    "        self.depth = 0\n",
    "        if max_depth < 1:\n",
    "            print(\"max_depth cannot be lower than 1! Setting it to 1.\")\n",
    "            max_depth = 1\n",
    "        self.max_depth = max_depth\n",
    "        self.longest_path_len = 0\n",
    "\n",
    "    def build_tree(self, X, Y, attribute_names, attribute_list=[], current_depth=0,\n",
    "                   parent_info={\"max_info_gain\": None, \"attribute_list[max_attribute]\": None, \"value\": None}):\n",
    "        if current_depth > self.longest_path_len:\n",
    "            self.longest_path_len = current_depth\n",
    "        if current_depth >= self.max_depth or len(attribute_list) == 0 or len(np.unique(Y)) == 1:\n",
    "            vals, counts = np.unique(Y, return_counts=True)\n",
    "            return TreeNode(None, None, True, vals[np.argmax(counts)], current_depth,\n",
    "                            parent_info[\"max_info_gain\"], parent_info[\"attribute_list[max_attribute]\"],\n",
    "                            parent_info[\"value\"])\n",
    "\n",
    "        max_info_gain = -1\n",
    "        max_attribute = None\n",
    "        i = 0\n",
    "        for attribute in attribute_list:\n",
    "            info_gain, entropy_attribute, entropy_parent = self.calculate_information_gain(X, Y, attribute)\n",
    "            if info_gain > max_info_gain:\n",
    "                max_info_gain = info_gain\n",
    "                max_attribute = i\n",
    "                entropy = entropy_parent\n",
    "            i += 1\n",
    "\n",
    "        vals, counts = np.unique(Y, return_counts=True)\n",
    "        root = TreeNode(attribute_list[max_attribute], attribute_names[attribute_list[max_attribute]],\n",
    "                        False, vals[np.argmax(counts)], current_depth,\n",
    "                        parent_info[\"max_info_gain\"], parent_info[\"attribute_list[max_attribute]\"],\n",
    "                        parent_info[\"value\"])\n",
    "\n",
    "        attribute_values = np.unique(X[:, attribute_list[max_attribute]])\n",
    "        new_attribute_list = np.delete(attribute_list, max_attribute)\n",
    "        for value in attribute_values:\n",
    "            indices = np.where(X[:, attribute_list[max_attribute]] == value)[0]\n",
    "            if len(indices) == 0:\n",
    "                root.add_child(TreeNode(None, None, True, vals[np.argmax(counts)], current_depth + 1,\n",
    "                                        max_info_gain, attribute_list[max_attribute], value), current_depth)\n",
    "            else:\n",
    "                parent_info = {\n",
    "                    \"max_info_gain\": max_info_gain,\n",
    "                    \"attribute_list[max_attribute]\": entropy,\n",
    "                    \"value\": value\n",
    "                }\n",
    "                root.add_child(self.build_tree(X[indices], Y[indices], attribute_names, new_attribute_list,\n",
    "                                               current_depth + 1, parent_info), value)\n",
    "        return root\n",
    "\n",
    "    def calculate_entropy(self, counts):\n",
    "        total = sum(counts)\n",
    "        entropy_value = 0\n",
    "        for element in counts:\n",
    "            p = (element / total)\n",
    "            if p != 0:\n",
    "                entropy_value -= p * np.log2(p)\n",
    "        return entropy_value\n",
    "\n",
    "    def calculate_information_gain(self, X, Y, attribute):\n",
    "        _, counts = np.unique(Y, return_counts=True)\n",
    "        entropy_attribute = self.calculate_entropy(counts)\n",
    "        entropy_parent = 0\n",
    "        distinct_attr_values = list(set(X[:, attribute]))\n",
    "        for val in distinct_attr_values:\n",
    "            indices = np.where(X[:, attribute] == val)[0]\n",
    "            _, counts = np.unique(Y[indices], return_counts=True)\n",
    "            entr = self.calculate_entropy(counts)\n",
    "            entropy_parent += (len(indices) / len(Y)) * entr\n",
    "        info_gain = entropy_attribute - entropy_parent\n",
    "        return info_gain, entropy_attribute, entropy_parent\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        attribute_names = list(range(X.shape[1]))  # Assume attributes are indexed\n",
    "        attribute_list = np.arange(X.shape[1])\n",
    "        self.root = self.build_tree(X, Y, attribute_names, attribute_list, 0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            predictions.append(self.root.predict(x))\n",
    "        return predictions\n",
    "\n",
    "    def get_longest_path_len(self):\n",
    "        return self.longest_path_len\n",
    "\n",
    "    def get_root_attribute(self):\n",
    "        if self.root:\n",
    "            return self.root.get_attribute()\n",
    "        return None\n",
    "\n",
    "    def print_tree(self):\n",
    "        self.root.print_node(\"\")\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv(\"C:\\\\Santhosh\\\\ML\\\\bank-4\\\\train.csv\")\n",
    "X_train = train_df.drop('y', axis=1)\n",
    "y_train = train_df['y']\n",
    "\n",
    "test_df = pd.read_csv(\"C:\\\\Santhosh\\\\ML\\\\bank-4\\\\test.csv\")\n",
    "X_test = test_df.drop('y', axis=1)\n",
    "y_test = test_df['y']\n",
    "\n",
    "# Calculate average errors for each criterion and varying maximum tree depths\n",
    "max_depth_range = list(range(1, 16))\n",
    "criterion_list = ['information_gain', 'majority_error', 'gini']\n",
    "results = {criterion: [] for criterion in criterion_list}\n",
    "\n",
    "for criterion in criterion_list:\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    for max_depth in max_depth_range:\n",
    "        model = DecisionTreeClassifier(max_depth=max_depth)\n",
    "        model.fit(X_train.values, y_train.values)\n",
    "        y_train_pred = model.predict(X_train.values)\n",
    "        y_test_pred = model.predict(X_test.values)\n",
    "\n",
    "        train_acc = accuracy_score(y_train, y_train_pred)\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "        train_errors.append(1 - train_acc)\n",
    "        test_errors.append(1 - test_acc)\n",
    "\n",
    "    results[criterion] = (train_errors, test_errors)\n",
    "\n",
    "# Print results in a table\n",
    "print('{:<12} {:<12} {:<12}'.format('Maximum Depth', 'Trainingg Error', 'Testingg Error'))\n",
    "for i in range(len(max_depth_range)):\n",
    "    print('{:<12} {:<12.3f} {:<12.3f}'.format(\n",
    "        max_depth_range[i],\n",
    "        results['information_gain'][1][i],\n",
    "        results['majority_error'][1][i],\n",
    "        results['gini'][1][i]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288f638f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
