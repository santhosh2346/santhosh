{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2992c59b-ee64-425a-bca1-7d51274c2632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variance: 0.01\n",
      "Training Error: 0.13470609127247415, Test Error: 0.13675505984189482\n",
      "\n",
      "Variance: 0.1\n",
      "Training Error: 0.13463728139231204, Test Error: 0.1366973154899521\n",
      "\n",
      "Variance: 0.5\n",
      "Training Error: 0.13455848104070045, Test Error: 0.13661158186034514\n",
      "\n",
      "Variance: 1\n",
      "Training Error: 0.13458173581836844, Test Error: 0.13663889673784446\n",
      "\n",
      "Variance: 3\n",
      "Training Error: 0.13461425511736783, Test Error: 0.13666465232535688\n",
      "\n",
      "Variance: 5\n",
      "Training Error: 0.13457055644598187, Test Error: 0.13661149390438065\n",
      "\n",
      "Variance: 10\n",
      "Training Error: 0.13459407414212837, Test Error: 0.13664396475232599\n",
      "\n",
      "Variance: 100\n",
      "Training Error: 0.13463118945805094, Test Error: 0.13668115840009648\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the training dataset\n",
    "def load_train_data():\n",
    "    \n",
    "    data = pd.read_csv(\"C:\\\\Users\\\\santhosh\\\\Downloads\\\\project\\\\santhosh\\\\Logistic-Regression\\\\dataset\\\\bank-note\\\\train.csv\")\n",
    "\n",
    "    # Assuming the last column is the target variable\n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Load the test dataset\n",
    "def load_test_data():\n",
    "    \n",
    "    data = pd.read_csv(\"C:\\\\Users\\\\santhosh\\\\Downloads\\\\project\\\\santhosh\\\\Logistic-Regression\\\\dataset\\\\bank-note\\\\test.csv\")\n",
    "\n",
    "    # Assuming the last column is the target variable\n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Logistic Regression functions\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def compute_error(X, y, w):\n",
    "    # Compute the logistic regression error\n",
    "    y_pred = sigmoid(np.dot(X, w))\n",
    "    error = -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
    "    return error\n",
    "\n",
    "# Main logistic regression with ML estimation\n",
    "def logistic_regression_ML(X_train, y_train, X_test, y_test):\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Initialize parameters\n",
    "    num_epochs = 100\n",
    "    w = np.zeros(X_train.shape[1])\n",
    "\n",
    "    # Learning rate schedule parameters\n",
    "    gamma0 = 0.01\n",
    "    d = 10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle training data\n",
    "        permutation = np.random.permutation(len(y_train))\n",
    "        X_train_shuffled = X_train[permutation]\n",
    "        y_train_shuffled = y_train[permutation]\n",
    "\n",
    "        for t, (x_n, y_n) in enumerate(zip(X_train_shuffled, y_train_shuffled)):\n",
    "            # Compute sigmoid\n",
    "            sigmoid_value = sigmoid(np.dot(w, x_n))\n",
    "\n",
    "            # Compute gradient\n",
    "            gradient = -(y_n - sigmoid_value) * x_n\n",
    "\n",
    "            # Update learning rate\n",
    "            learning_rate = gamma0 / (1 + (gamma0 / d) * (epoch * len(y_train) + t))\n",
    "\n",
    "            # Update weights\n",
    "            w -= learning_rate * gradient\n",
    "\n",
    "    # Evaluate on training and test sets\n",
    "    train_error = compute_error(X_train, y_train, w)\n",
    "    test_error = compute_error(X_test, y_test, w)\n",
    "\n",
    "    return train_error, test_error\n",
    "\n",
    "# Main code for ML estimation with different prior variances\n",
    "if __name__ == \"__main__\":\n",
    "    # Load training data\n",
    "    X_train, y_train = load_train_data()\n",
    "\n",
    "    # Load test data\n",
    "    X_test, y_test = load_test_data()\n",
    "\n",
    "    # Prior variances to test\n",
    "    prior_variances = [0.01, 0.1, 0.5, 1, 3, 5, 10, 100]\n",
    "\n",
    "    for prior_variance in prior_variances:\n",
    "        print(f\"\\nVariance: {prior_variance}\")\n",
    "        \n",
    "        # Perform logistic regression with ML estimation\n",
    "        train_error, test_error = logistic_regression_ML(X_train, y_train, X_test, y_test)\n",
    "        print(f\"Training Error: {train_error}, Test Error: {test_error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430167a8-e68c-4224-9c3a-75e1252c228c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
