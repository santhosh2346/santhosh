{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86c23ad-d332-45f7-a3c4-a1adaf8e66e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance: 0.01, Training Error: 0.691399056176157, Test Error: 0.6913098259267894\n",
      "Variance: 0.1, Training Error: 0.675505135906775, Test Error: 0.6746391362091789\n",
      "Variance: 0.5, Training Error: 0.6206348125855594, Test Error: 0.6173671808469793\n",
      "Variance: 1, Training Error: 0.5720533480464409, Test Error: 0.5671284261135525\n",
      "Variance: 3, Training Error: 0.46439709659056233, Test Error: 0.4579817876341264\n",
      "Variance: 5, Training Error: 0.40656145363981167, Test Error: 0.4006901256645244\n",
      "Variance: 10, Training Error: 0.32697792927938635, Test Error: 0.32306925215688365\n",
      "Variance: 100, Training Error: 0.16234603773708622, Test Error: 0.16374857716664803\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the training dataset\n",
    "def load_train_data():\n",
    "    \n",
    "    data = pd.read_csv(\"C:\\\\Users\\\\santhosh\\\\Downloads\\\\project\\\\santhosh\\\\Logistic-Regression\\\\dataset\\\\bank-note\\\\train.csv\")\n",
    "    \n",
    "    # Assuming the last column is the target variable\n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Load the test dataset\n",
    "def load_test_data():\n",
    "    \n",
    "    data = pd.read_csv(\"C:\\\\Users\\\\santhosh\\\\Downloads\\\\project\\\\santhosh\\\\Logistic-Regression\\\\dataset\\\\bank-note\\\\test.csv\")\n",
    "\n",
    "    # Assuming the last column is the target variable\n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Logistic Regression functions\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def compute_error(X, y, w):\n",
    "    # Compute the logistic regression error\n",
    "    y_pred = sigmoid(np.dot(X, w))\n",
    "    error = -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
    "    return error\n",
    "\n",
    "# Main logistic regression with MAP estimation\n",
    "def logistic_regression_MAP(X_train, y_train, X_test, y_test, prior_variance):\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Initialize parameters\n",
    "    num_epochs = 100\n",
    "    w = np.zeros(X_train.shape[1])\n",
    "\n",
    "    # Learning rate schedule parameters\n",
    "    gamma0 = 0.01\n",
    "    d = 10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle training data\n",
    "        permutation = np.random.permutation(len(y_train))\n",
    "        X_train_shuffled = X_train[permutation]\n",
    "        y_train_shuffled = y_train[permutation]\n",
    "\n",
    "        for t, (x_n, y_n) in enumerate(zip(X_train_shuffled, y_train_shuffled)):\n",
    "            # Compute sigmoid\n",
    "            sigmoid_value = sigmoid(np.dot(w, x_n))\n",
    "\n",
    "            # Compute gradient\n",
    "            gradient = -(y_n - sigmoid_value) * x_n + (1 / prior_variance) * w\n",
    "\n",
    "            # Update learning rate\n",
    "            learning_rate = gamma0 / (1 + (gamma0 / d) * (epoch * len(y_train) + t))\n",
    "\n",
    "            # Update weights\n",
    "            w -= learning_rate * gradient\n",
    "\n",
    "    # Evaluate on training and test sets\n",
    "    train_error = compute_error(X_train, y_train, w)\n",
    "    test_error = compute_error(X_test, y_test, w)\n",
    "\n",
    "    return train_error, test_error\n",
    "\n",
    "# Main code\n",
    "if __name__ == \"__main__\":\n",
    "    # Load training data\n",
    "    X_train, y_train = load_train_data()\n",
    "\n",
    "    # Load test data\n",
    "    X_test, y_test = load_test_data()\n",
    "\n",
    "    # Prior variances to test\n",
    "    prior_variances = [0.01, 0.1, 0.5, 1, 3, 5, 10, 100]\n",
    "\n",
    "    # Perform logistic regression for each prior variance\n",
    "    for prior_variance in prior_variances:\n",
    "        train_error, test_error = logistic_regression_MAP(X_train, y_train, X_test, y_test, prior_variance)\n",
    "        print(f\"Variance: {prior_variance}, Training Error: {train_error}, Test Error: {test_error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b88c884-88fa-473c-9382-d942cded9299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
